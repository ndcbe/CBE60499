{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_HEADER-->\n",
    "*This notebook contains material from [CBE60499](https://ndcbe.github.io/CBE60499);\n",
    "content is available [on Github](git@github.com:ndcbe/CBE60499.git).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [3.8 Algorithms Homework 1](https://ndcbe.github.io/CBE60499/03.08-Algorithms1.html) | [Contents](toc.html) | [Tag Index](tag_index.html) | [3.10 Algorithms Homework 3](https://ndcbe.github.io/CBE60499/03.10-Algorithms3.html) ><p><a href=\"https://colab.research.google.com/github/ndcbe/CBE60499/blob/master/docs/03.09-Algorithms2.ipynb\"> <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a><p><a href=\"https://ndcbe.github.io/CBE60499/03.09-Algorithms2.ipynb\"> <img align=\"left\" src=\"https://img.shields.io/badge/Github-Download-blue.svg\" alt=\"Download\" title=\"Download Notebook\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 1,
     "link": "[3.9 Algorithms Homework 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9-Algorithms-Homework-2)",
     "section": "3.9 Algorithms Homework 2"
    }
   },
   "source": [
    "# 3.9 Algorithms Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 1,
     "link": "[3.9 Algorithms Homework 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9-Algorithms-Homework-2)",
     "section": "3.9 Algorithms Homework 2"
    }
   },
   "source": [
    "**Important for Spring 2021**: We are skipping this homework assignment. The Python solutions will be posted to Sakai. Please use this as exam study material.\n",
    "\n",
    "Homework solutions are copyright Alex Dowling (2021). You MAY NOT share them with anyone (post online, etc.) without written permission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 1,
     "link": "[3.9 Algorithms Homework 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9-Algorithms-Homework-2)",
     "section": "3.9 Algorithms Homework 2"
    }
   },
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import matplotlib as plat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import sympy as sym\n",
    "# from sympy import symbols, diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.1 Finite Difference Approximations](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1-Finite-Difference-Approximations)",
     "section": "3.9.1 Finite Difference Approximations"
    }
   },
   "source": [
    "## 3.9.1 Finite Difference Approximations\n",
    "\n",
    "**Main Idea**: Explore the accuracy of the finite difference approximation for $\\nabla f(x)$ and $\\nabla^2 f(x)$ from Example 2.19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.1 Finite difference order](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.1-Finite-difference-order)",
     "section": "3.9.1.1 Finite difference order"
    },
    "tags": [
     "gradescope"
    ]
   },
   "source": [
    "### 3.9.1.1 Finite difference order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.1 Finite difference order](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.1-Finite-difference-order)",
     "section": "3.9.1.1 Finite difference order"
    }
   },
   "source": [
    "Repeat the analysis from class to show the backward and central finite difference truncations errors are $\\mathcal{O}(\\epsilon)$ and $\\mathcal{O}(\\epsilon^2)$, respectively. We discussed these error orders graphically. Please use a Taylor series for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.2 Provided Codes](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2-Provided-Codes)",
     "section": "3.9.1.2 Provided Codes"
    }
   },
   "source": [
    "### 3.9.1.2 Provided Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.2 Provided Codes](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2-Provided-Codes)",
     "section": "3.9.1.2 Provided Codes"
    }
   },
   "source": [
    "Please review the following code. You do not need to turn anything in for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.1 Finite Difference Code](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.1-Finite-Difference-Code)",
     "section": "3.9.1.2.1 Finite Difference Code"
    }
   },
   "source": [
    "#### 3.9.1.2.1 Finite Difference Code\n",
    "\n",
    "The code below has been adapted from the finite difference examples presented in class. Notice the second input is a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.1 Finite Difference Code](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.1-Finite-Difference-Code)",
     "section": "3.9.1.2.1 Finite Difference Code"
    }
   },
   "outputs": [],
   "source": [
    "## Define Python function\n",
    "def my_f(x,verbose=False):\n",
    "    ''' Evaluate function given above at point x\n",
    "\n",
    "    Inputs:\n",
    "        x - vector with 2 elements\n",
    "        \n",
    "    Outputs:\n",
    "        f - function value (scalar)\n",
    "    '''\n",
    "    # Constants\n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    c = np.array([40, 1, 10])\n",
    "    \n",
    "    # Intermediates. Recall Python indicies start at 0\n",
    "    u = x[0] - 0.8\n",
    "    s = np.sqrt(1-u)\n",
    "    s2 = np.sqrt(1+u)\n",
    "    v = x[1] -(a[0] + a[1]*u**2*s-a[2]*u)\n",
    "    alpha = -b[0] + b[1]*u**2*s2+ b[2]*u \n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"##### my_f at x = \",x, \"#####\")\n",
    "        print(\"u = \",u)\n",
    "        print(\"sqrt(1-u) = \",s)\n",
    "        print(\"sqrt(1+u) = \",s2)\n",
    "        print(\"v = \",v)\n",
    "        print(\"alpha = \",alpha)\n",
    "        print(\"beta = \",beta)\n",
    "        print(\"f(x) = \",)\n",
    "        print(\"##### Done. #####\\n\")\n",
    "    \n",
    "    return alpha*np.exp(-beta)\n",
    "\n",
    "## Calculate gradient with central finite difference\n",
    "def my_grad_approx(x,f,eps1,verbose=False):\n",
    "    '''\n",
    "    Calculate gradient of function my_f using central difference formula\n",
    "    \n",
    "    Inputs:\n",
    "        x - point for which to evaluate gradient\n",
    "        f - function to consider\n",
    "        eps1 - perturbation size\n",
    "        \n",
    "    Outputs:\n",
    "        grad - gradient (vector)\n",
    "    '''\n",
    "    \n",
    "    n = len(x)\n",
    "    grad = np.zeros(n)\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"***** my_grad_approx at x = \",x,\"*****\")\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        \n",
    "        # Create vector of zeros except eps in position i\n",
    "        e = np.zeros(n)\n",
    "        e[i] = eps1\n",
    "        \n",
    "        # Finite difference formula\n",
    "        my_f_plus = f(x + e)\n",
    "        my_f_minus = f(x - e)\n",
    "        \n",
    "        # Diagnostics\n",
    "        if(verbose):\n",
    "            print(\"e[\",i,\"] = \",e)\n",
    "            print(\"f(x + e[\",i,\"]) = \",my_f_plus)\n",
    "            print(\"f(x - e[\",i,\"]) = \",my_f_minus)\n",
    "        \n",
    "        \n",
    "        grad[i] = (my_f_plus - my_f_minus)/(2*eps1)\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"***** Done. ***** \\n\")\n",
    "    \n",
    "    return grad\n",
    "\n",
    "## Calculate gradient using central finite difference and my_hes_approx\n",
    "def my_hes_approx(x,grad,eps2):\n",
    "    '''\n",
    "    Calculate gradient of function my_f using central difference formula and my_grad\n",
    "    \n",
    "    Inputs:\n",
    "        x - point for which to evaluate gradient\n",
    "        grad - function to calculate the gradient\n",
    "        eps2 - perturbation size (for Hessian NOT gradient approximation)\n",
    "        \n",
    "    Outputs:\n",
    "        H - Hessian (matrix)\n",
    "    '''\n",
    "    \n",
    "    n = len(x)\n",
    "    H = np.zeros([n,n])\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        # Create vector of zeros except eps in position i\n",
    "        e = np.zeros(n)\n",
    "        e[i] = eps2\n",
    "        \n",
    "        # Evaluate gradient twice\n",
    "        grad_plus = grad(x + e)\n",
    "        grad_minus = grad(x - e)\n",
    "        \n",
    "        # Notice we are building the Hessian by column (or row)\n",
    "        H[:,i] = (grad_plus - grad_minus)/(2*eps2)\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.1 Finite Difference Code](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.1-Finite-Difference-Code)",
     "section": "3.9.1.2.1 Finite Difference Code"
    }
   },
   "outputs": [],
   "source": [
    "### Test the functions from above\n",
    "\n",
    "## Define test point\n",
    "xt = np.array([0,0])\n",
    "print(\"xt = \",xt,\"\\n\")\n",
    "\n",
    "print(\"f(xt) = \\n\",my_f([0,0]),\"\\n\")\n",
    "\n",
    "## Compute gradient\n",
    "g = my_grad_approx(xt,my_f,1E-6)\n",
    "print(\"grad(xt) = \",g,\"\\n\")\n",
    "\n",
    "## Compute Hessian\n",
    "# Step 1: Create a Lambda (anonymous) function\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Step 2: Calculate Hessian approximation\n",
    "H = my_hes_approx(xt,calc_grad,1E-6)\n",
    "print(\"hes(xt) = \\n\",H,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.2 Analytic Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.2-Analytic-Gradient)",
     "section": "3.9.1.2.2 Analytic Gradient"
    }
   },
   "source": [
    "#### 3.9.1.2.2 Analytic Gradient\n",
    "\n",
    "It turns out that calculating the analytic gradient with Mathematic quickly becomes a mess. Instead, the  following code uses the symbolic computing capabilities in SymPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.2 Analytic Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.2-Analytic-Gradient)",
     "section": "3.9.1.2.2 Analytic Gradient"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Encoding the exact gradient with the long expression above is very time-consuming. This is a trick of calculating the \n",
    "symbolic derivative and converting it to an analytic function to be evaluated at a point. \n",
    "'''\n",
    "\n",
    "# Define function to use with symbolic computing framework\n",
    "def f(x1,x2):\n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    b1 = 5;\n",
    "    c = np.array([40, 1, 10])\n",
    "    u = x1 - 0.8\n",
    "    v = x2 -(a[0] + a[1]*u**2*(1-u)**0.5-a[2]*u)\n",
    "    alpha = b[1]*u**2*(1+u)**0.5 + b[2]*u -b[0]\n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    return alpha*sym.exp(-1*beta)\n",
    "\n",
    "# Define function to use later\n",
    "def my_grad_exact(x):\n",
    "    x1, x2 = sym.symbols('x1 x2')\n",
    "    DerivativeOfF1 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1));\n",
    "    DerivativeOfF2 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2));\n",
    "    #DerivativeOfF2 = sym.lambdify((x1,x2),gradf2(x1,x2));\n",
    "    #F = sym.lambdify((x1,x2),f(x1,x2));\n",
    "    return np.array([DerivativeOfF1(x[0],x[1]),DerivativeOfF2(x[0],x[1])])\n",
    "    \n",
    "x = np.array([0,0])\n",
    "print(\"The exact gradient is \\n\",my_grad_exact(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.3 Analytic Hessian](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.3-Analytic-Hessian)",
     "section": "3.9.1.2.3 Analytic Hessian"
    }
   },
   "source": [
    "#### 3.9.1.2.3 Analytic Hessian\n",
    "\n",
    "The code below assembles the analytic Hessian using the symbolic computing framework in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.3 Analytic Hessian](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.3-Analytic-Hessian)",
     "section": "3.9.1.2.3 Analytic Hessian"
    }
   },
   "outputs": [],
   "source": [
    "def f(x1,x2):\n",
    "    \n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    b1 = 5;\n",
    "    c = np.array([40, 1, 10])\n",
    "    u = x1 - 0.8\n",
    "    v = x2 -(a[0] + a[1]*u**2*(1-u)**0.5-a[2]*u)\n",
    "    alpha = b[1]*u**2*(1+u)**0.5 + b[2]*u -b[0]\n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    return alpha*sym.exp(-1*beta)\n",
    "\n",
    "\n",
    "def my_hes_exact(x):\n",
    "    x1, x2 = sym.symbols('x1 x2')\n",
    "    HessianOfF11 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1,x1));\n",
    "    HessianOfF12 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1,x2));\n",
    "    HessianOfF21 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2,x1));\n",
    "    HessianOfF22 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2,x2));\n",
    "    #DerivativeOfF2 = sym.lambdify((x1,x2),gradf2(x1,x2));\n",
    "    #F = sym.lambdify((x1,x2),f(x1,x2));\n",
    "    return np.array([[HessianOfF11(x[0],x[1]),HessianOfF12(x[0],x[1])],[HessianOfF21(x[0],x[1]),HessianOfF22(x[0],x[1])]])\n",
    "    \n",
    "x = np.array([0,0])\n",
    "print(\"The exact Hessian is \\n\",my_hes_exact(x))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.3 Gradient Finite Difference Comparison](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.3-Gradient-Finite-Difference-Comparison)",
     "section": "3.9.1.3 Gradient Finite Difference Comparison"
    }
   },
   "source": [
    "### 3.9.1.3 Gradient Finite Difference Comparison\n",
    "\n",
    "Repeat the analysis procedure from the finite difference class notebook to find the value of $\\epsilon_1$ that gives the smallest approximation error. Some tips:\n",
    "1. Write a `for` loop to iterate over many values of $\\epsilon_1$\n",
    "2. Use $|| \\nabla f(x;\\epsilon_1)_{approx} - \\nabla f(x)_{exact} ||$ to measure the error. Your choice on which norm(s) to use. Please label your plot with the norm(s) you used.\n",
    "3. Make a log-log plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.3 Gradient Finite Difference Comparison](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.3-Gradient-Finite-Difference-Comparison)",
     "section": "3.9.1.3 Gradient Finite Difference Comparison"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.4 Hessian Finite Difference using Approximate Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.4-Hessian-Finite-Difference-using-Approximate-Gradient)",
     "section": "3.9.1.4 Hessian Finite Difference using Approximate Gradient"
    }
   },
   "source": [
    "### 3.9.1.4 Hessian Finite Difference using Approximate Gradient\n",
    "\n",
    "Repeat the analysis from above. Use `my_grad_approx` and the best value for $\\epsilon_1$ you previously found. What value of $\\epsilon_2$ gives the lowest Hessian approximation error? Note: $\\epsilon_1$ is used in the gradient approximation and $\\epsilon_2$ is used in the Hessian approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.4 Hessian Finite Difference using Approximate Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.4-Hessian-Finite-Difference-using-Approximate-Gradient)",
     "section": "3.9.1.4 Hessian Finite Difference using Approximate Gradient"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.5 Hessian Finite Difference using Exact Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.5-Hessian-Finite-Difference-using-Exact-Gradient)",
     "section": "3.9.1.5 Hessian Finite Difference using Exact Gradient"
    }
   },
   "source": [
    "### 3.9.1.5 Hessian Finite Difference using Exact Gradient\n",
    "\n",
    "Repeat the analysis from above using `my_grad_exact`. What value of $\\epsilon_2$ gives the lower Hessian approximation error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.5 Hessian Finite Difference using Exact Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.5-Hessian-Finite-Difference-using-Exact-Gradient)",
     "section": "3.9.1.5 Hessian Finite Difference using Exact Gradient"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.6 Final Answers](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.6-Final-Answers)",
     "section": "3.9.1.6 Final Answers"
    }
   },
   "source": [
    "### 3.9.1.6 Final Answers\n",
    "\n",
    "**Record your final answers below**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.6 Final Answers](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.6-Final-Answers)",
     "section": "3.9.1.6 Final Answers"
    }
   },
   "source": [
    "A. Using $\\epsilon_1 = $ ... gives error $|| \\nabla f(x;\\epsilon_1)_{approx} - \\nabla f(x)_{exact} || = $ ...\n",
    "\n",
    "B. Using $\\epsilon_1 = $ ... and $\\epsilon_2 = $ ... gives error $|| \\nabla^2 f(x;\\epsilon_1,\\epsilon_2)_{approx} - \\nabla^2 f(x)_{exact} || = $ ...\n",
    "\n",
    "C. Using $\\epsilon_2 = $ gives error $|| \\nabla^2 f(x;\\epsilon_2)_{approx} - \\nabla^2 f(x)_{exact} || = $ ...\n",
    "\n",
    "These answers were computed using the ... norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.7-Discussion)",
     "section": "3.9.1.7 Discussion"
    }
   },
   "source": [
    "### 3.9.1.7 Discussion\n",
    "\n",
    "What is the benefit of using the *exact gradient* when approximating the Hessian with central finite difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.7-Discussion)",
     "section": "3.9.1.7 Discussion"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.2 Analysis of possible optimization solutions](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2-Analysis-of-possible-optimization-solutions)",
     "section": "3.9.2 Analysis of possible optimization solutions"
    }
   },
   "source": [
    "## 3.9.2 Analysis of possible optimization solutions\n",
    "\n",
    "Consider the following optimization problem:\n",
    "\n",
    "$$\\min f(x) := \\left[x_1^2 + (x_2 + 1)^2\\right] \\cdot \\left[x_1^2 + (x_2 - 1)^2\\right]$$\n",
    "\n",
    "Our optimization algorithm terminates at the following points:\n",
    "1. $x = [0,0]^T$\n",
    "2. $x = [0,1]^T$\n",
    "3. $x = [0,-1]^T$\n",
    "4. $x = [1,1]^T$\n",
    "\n",
    "Classify each point.\n",
    "\n",
    "You may solve this problem entirely on paper, entirely in Python, or some combination. Please record your answer below. (If you solve on paper, you can typeset the justification in 1 or 2 sentences.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.2 Analysis of possible optimization solutions](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2-Analysis-of-possible-optimization-solutions)",
     "section": "3.9.2 Analysis of possible optimization solutions"
    }
   },
   "source": [
    "**Suggested solution approach: define systematic analysis routine**\n",
    "\n",
    "Create a function that:\n",
    "1. Evaluates $f(x)$, $\\nabla f(x)$, and $\\nabla^2 f(x)$ for a given $x$\n",
    "2. Calculates eigenvalues of $\\nabla^2 f(x)$\n",
    "\n",
    "We then reuse this function to analyze each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.2 Analysis of possible optimization solutions](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2-Analysis-of-possible-optimization-solutions)",
     "section": "3.9.2 Analysis of possible optimization solutions"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.1 Point 1](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.1-Point-1)",
     "section": "3.9.2.1 Point 1"
    }
   },
   "source": [
    "### 3.9.2.1 Point 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.1 Point 1](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.1-Point-1)",
     "section": "3.9.2.1 Point 1"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.1 Point 1](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.1-Point-1)",
     "section": "3.9.2.1 Point 1"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.2 Point 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.2-Point-2)",
     "section": "3.9.2.2 Point 2"
    }
   },
   "source": [
    "### 3.9.2.2 Point 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.2 Point 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.2-Point-2)",
     "section": "3.9.2.2 Point 2"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.2 Point 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.2-Point-2)",
     "section": "3.9.2.2 Point 2"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.3 Point 3](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.3-Point-3)",
     "section": "3.9.2.3 Point 3"
    }
   },
   "source": [
    "### 3.9.2.3 Point 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.3 Point 3](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.3-Point-3)",
     "section": "3.9.2.3 Point 3"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.3 Point 3](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.3-Point-3)",
     "section": "3.9.2.3 Point 3"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.4 Point 4](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.4-Point-4)",
     "section": "3.9.2.4 Point 4"
    }
   },
   "source": [
    "### 3.9.2.4 Point 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.4 Point 4](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.4-Point-4)",
     "section": "3.9.2.4 Point 4"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.4 Point 4](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.4-Point-4)",
     "section": "3.9.2.4 Point 4"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.5 Visualize in 3D](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.5-Visualize-in-3D)",
     "section": "3.9.2.5 Visualize in 3D"
    }
   },
   "source": [
    "### 3.9.2.5 Visualize in 3D\n",
    "\n",
    "Plot $f(x)$ in 3D over the domain $x_1 \\in [-1.1,1.1]$ and $x_2 \\in [-1.5, 1.5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.5 Visualize in 3D](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.5-Visualize-in-3D)",
     "section": "3.9.2.5 Visualize in 3D"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.6 Convexity](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.6-Convexity)",
     "section": "3.9.2.6 Convexity"
    }
   },
   "source": [
    "### 3.9.2.6 Convexity\n",
    "\n",
    "\n",
    "Is $f(x)$ convex? Did you need to make the plot to make this determination? Write a sentence or two to justify your answer.\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.3 Multivariable Taylor Series](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3-Multivariable-Taylor-Series)",
     "section": "3.9.3 Multivariable Taylor Series"
    }
   },
   "source": [
    "## 3.9.3 Multivariable Taylor Series\n",
    "\n",
    "You will use `my_grad_exact`, `my_grad_approx`, `my_hes_exact`, and `my_hes_approx` to construct Taylor series approximations to an arbitrary twice differentiable continuous functions with inputs $x \\in \\mathbb{R}^2$. We will then consider Example 2.19 and visualize the Taylor series approximation in 3D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.1-Create-a-function-to-plot-the-first-order-Taylor-series-using-$\\nabla-f$)",
     "section": "3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$"
    }
   },
   "source": [
    "### 3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$\n",
    "\n",
    "Create a general function that:\n",
    "1. Constructs a Taylor series using $\\nabla f$ centered around a given point\n",
    "2. Plots the true function and Taylor series approximation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.1-Create-a-function-to-plot-the-first-order-Taylor-series-using-$\\nabla-f$)",
     "section": "3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$"
    }
   },
   "outputs": [],
   "source": [
    "def taylor1(xc, f, grad, dx):\n",
    "    '''\n",
    "    Constructs a Taylor series using first derivates and visualizes in 3D\n",
    "    \n",
    "    Arguments:\n",
    "        xc - point to center Taylor series\n",
    "        f - function that computes function value. Only has one input (x)\n",
    "        grad - function that computes gradient. Only has one input (x)\n",
    "        dx - list or numpy array. creates 3D plot over xc[0] +/- dx[0], xc[1] +/- dx[1]\n",
    "    \n",
    "    Returns:\n",
    "        none\n",
    "        \n",
    "    Actions:\n",
    "        3D plot\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.2 Taylor Series using `my_grad_approx`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.2-Taylor-Series-using-`my_grad_approx`)",
     "section": "3.9.3.2 Taylor Series using `my_grad_approx`"
    }
   },
   "source": [
    "### 3.9.3.2 Taylor Series using `my_grad_approx`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.5, 0.5]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.2 Taylor Series using `my_grad_approx`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.2-Taylor-Series-using-`my_grad_approx`)",
     "section": "3.9.3.2 Taylor Series using `my_grad_approx`"
    }
   },
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.5, 0.5]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor1(xc, my_f, calc_grad, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.3 Taylor Series using `my_grad_exact`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.3-Taylor-Series-using-`my_grad_exact`)",
     "section": "3.9.3.3 Taylor Series using `my_grad_exact`"
    }
   },
   "source": [
    "### 3.9.3.3 Taylor Series using `my_grad_exact`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.5, 0.5]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.3 Taylor Series using `my_grad_exact`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.3-Taylor-Series-using-`my_grad_exact`)",
     "section": "3.9.3.3 Taylor Series using `my_grad_exact`"
    }
   },
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_exact(x)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.5, 0.5]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor1(xc, my_f, calc_grad, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.4-Create-a-function-to-plot-the-second-order-Taylor-series-using-$\\nabla-f$-and-$\\nabla^2-f$)",
     "section": "3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$"
    }
   },
   "source": [
    "### 3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.4-Create-a-function-to-plot-the-second-order-Taylor-series-using-$\\nabla-f$-and-$\\nabla^2-f$)",
     "section": "3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$"
    }
   },
   "outputs": [],
   "source": [
    "def taylor2(xc, f, grad, hes, dx):\n",
    "    '''\n",
    "    Constructs a Taylor series using first derivates and visualizes in 3D\n",
    "    \n",
    "    Inputs:\n",
    "        xc - point to center Taylor series\n",
    "        f - computes function value. Only has one input (x)\n",
    "        grad - computes gradient. Only has one input (x)\n",
    "        hes - computes the Hessian. Only has one input (x)\n",
    "        dx - creates 3D plot over xc[0] +/- dx[0], xc[1] +/- dx[1]\n",
    "    \n",
    "    Outputs:\n",
    "        none\n",
    "        \n",
    "    Creates:\n",
    "        3D plot\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### Evaluates function and gradiant\n",
    "    fval = f(xc)\n",
    "    gval = grad(xc)\n",
    "    Hval = hes(xc)\n",
    "    \n",
    "    ### Creates domain for plotting\n",
    "    x1 = np.arange(xc[0] - dx[0],xc[0] + dx[0],dx[0]/100)\n",
    "    x2 = np.arange(xc[1] - dx[1],xc[1] + dx[1],dx[1]/100)\n",
    "    \n",
    "    ## Create a matrix of all points to sample\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "    n1 = len(x1)\n",
    "    n2 = len(x2)\n",
    "\n",
    "    ## Allocate matrix for true function value\n",
    "    F = np.zeros([n2, n1])\n",
    "\n",
    "    ## Allocate matrix for Taylor series approximation\n",
    "    T = np.zeros([n2, n1])    \n",
    "    \n",
    "    xtemp = np.zeros(2)\n",
    "\n",
    "    # Evaluate f(x) and Taylor series over grid\n",
    "    for i in range(0,n1):\n",
    "        xtemp[0] = x1[i]\n",
    "        for j in range(0,n2):\n",
    "            xtemp[1] = x2[j]\n",
    "            \n",
    "            # Evaluate f(x)\n",
    "            F[j,i] = my_f(xtemp)\n",
    "\n",
    "            # Evaluate Taylor series\n",
    "            dx_ = xtemp - xc\n",
    "            \n",
    "            '''\n",
    "            print(\"dx = \",dx)\n",
    "            print(\"gval = \",gval)\n",
    "            print(\"Hval = \",Hval)\n",
    "            '''\n",
    "            \n",
    "            temp = Hval.dot(dx_)\n",
    "            # print(\"Hval * dx = \",temp)\n",
    "            \n",
    "            \n",
    "            # T[j,i] = fval + gval.dot(dx_) + 0.5*(temp).dot(dx_)\n",
    "            T[j,i] = fval + gval.dot(dx_) + 0.5*(dx_.dot(Hval.dot(dx_)))\n",
    "            \n",
    "    # Create 3D figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Plot f(x)\n",
    "    surf = ax.plot_surface(X1, X2, F, linewidth=0,cmap=cm.coolwarm,antialiased=True,label=\"f(x)\")\n",
    "\n",
    "    # Plot Taylor series approximation\n",
    "    surf = ax.plot_surface(X1, X2, T, linewidth=0,cmap=cm.PiYG,antialiased=True,label=\"Taylor series\")\n",
    "    \n",
    "    # Add candidate point\n",
    "    ax.scatter(xc[0],xc[1],fval,s=50,color=\"black\",depthshade=True)\n",
    "\n",
    "    # Draw vertical line through stationary point to help visualization\n",
    "    # Maximum value in array\n",
    "    fmax = np.amax(F)\n",
    "    fmin = np.amin(F)\n",
    "    ax.plot([xc[0], xc[0]], [xc[1], xc[1]], [fmin,fmax],color=\"black\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.5-Taylor-series-using-`my_grad_approx`-and-`my_hes_approx`)",
     "section": "3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`"
    }
   },
   "source": [
    "### 3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.2, 0.2]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.5-Taylor-series-using-`my_grad_approx`-and-`my_hes_approx`)",
     "section": "3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`"
    }
   },
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Specify epsilon2\n",
    "calc_hes = lambda x : my_hes_approx(x, calc_grad, 1E-6)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.2, 0.2]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor2(xc, my_f, calc_grad, calc_hes, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.6-Taylor-series-using-`my_grad_exact`-and-`my_hes_exact`)",
     "section": "3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`"
    }
   },
   "source": [
    "### 3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.2, 0.2]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.6-Taylor-series-using-`my_grad_exact`-and-`my_hes_exact`)",
     "section": "3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([0,0])\n",
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_exact(x)\n",
    "\n",
    "# Specify epsilon2\n",
    "calc_hes = lambda x1 : my_hes_exact(x1)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.2, 0.2]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor2(xc, my_f, calc_grad, calc_hes, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "### 3.9.3.7 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "Write 1 or 2 sentences to describe the the shapes for the first order and second order Taylor series approximations? Why do these shapes make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "Is there a visible difference in the Taylor series approximations using the finite difference versus exact derivatives? Why does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [3.8 Algorithms Homework 1](https://ndcbe.github.io/CBE60499/03.08-Algorithms1.html) | [Contents](toc.html) | [Tag Index](tag_index.html) | [3.10 Algorithms Homework 3](https://ndcbe.github.io/CBE60499/03.10-Algorithms3.html) ><p><a href=\"https://colab.research.google.com/github/ndcbe/CBE60499/blob/master/docs/03.09-Algorithms2.ipynb\"> <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a><p><a href=\"https://ndcbe.github.io/CBE60499/03.09-Algorithms2.ipynb\"> <img align=\"left\" src=\"https://img.shields.io/badge/Github-Download-blue.svg\" alt=\"Download\" title=\"Download Notebook\"></a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
