{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_HEADER-->\n",
    "*This notebook contains material from [CBE60499](https://ndcbe.github.io/CBE60499);\n",
    "content is available [on Github](git@github.com:ndcbe/CBE60499.git).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [3.8 Algorithms 1 Homework](https://ndcbe.github.io/CBE60499/03.08-Algorithms1.html) | [Contents](toc.html) | [4.0 Constrained Nonlinear Optimization: Theory and Applications](https://ndcbe.github.io/CBE60499/04.00-Constrained.html) ><p><a href=\"https://colab.research.google.com/github/ndcbe/CBE60499/blob/master/docs/03.09-Algorithms2.ipynb\"> <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a><p><a href=\"https://ndcbe.github.io/CBE60499/03.09-Algorithms2.ipynb\"> <img align=\"left\" src=\"https://img.shields.io/badge/Github-Download-blue.svg\" alt=\"Download\" title=\"Download Notebook\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 1,
     "link": "[3.9 Algorithms Homework 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9-Algorithms-Homework-2)",
     "section": "3.9 Algorithms Homework 2"
    }
   },
   "source": [
    "# 3.9 Algorithms Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 1,
     "link": "[3.9 Algorithms Homework 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9-Algorithms-Homework-2)",
     "section": "3.9 Algorithms Homework 2"
    }
   },
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import matplotlib as plat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import sympy as sym\n",
    "# from sympy import symbols, diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.1 Finite Difference Approximations](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1-Finite-Difference-Approximations)",
     "section": "3.9.1 Finite Difference Approximations"
    }
   },
   "source": [
    "## 3.9.1 Finite Difference Approximations\n",
    "\n",
    "**Main Idea**: Explore the accuracy of the finite difference approximation for $\\nabla f(x)$ and $\\nabla^2 f(x)$ from Example 2.19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.1 Finite difference order](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.1-Finite-difference-order)",
     "section": "3.9.1.1 Finite difference order"
    }
   },
   "source": [
    "### 3.9.1.1 Finite difference order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.1 Finite difference order](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.1-Finite-difference-order)",
     "section": "3.9.1.1 Finite difference order"
    }
   },
   "source": [
    "Repeat the analysis from class to show the backward and central finite difference truncations errors are $\\mathcal{O}(\\epsilon)$ and $\\mathcal{O}(\\epsilon^2)$, respectively. We discussed these error orders graphically. Please use a Taylor series for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.2 Provided Codes](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2-Provided-Codes)",
     "section": "3.9.1.2 Provided Codes"
    }
   },
   "source": [
    "### 3.9.1.2 Provided Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.2 Provided Codes](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2-Provided-Codes)",
     "section": "3.9.1.2 Provided Codes"
    }
   },
   "source": [
    "Please review the following code. You do not need to turn anything in for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.1 Finite Difference Code](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.1-Finite-Difference-Code)",
     "section": "3.9.1.2.1 Finite Difference Code"
    }
   },
   "source": [
    "#### 3.9.1.2.1 Finite Difference Code\n",
    "\n",
    "The code below has been adapted the finite difference examples presented in class. Notice the second input is a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.1 Finite Difference Code](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.1-Finite-Difference-Code)",
     "section": "3.9.1.2.1 Finite Difference Code"
    }
   },
   "outputs": [],
   "source": [
    "## Define Python function\n",
    "def my_f(x,verbose=False):\n",
    "    ''' Evaluate function given above at point x\n",
    "\n",
    "    Inputs:\n",
    "        x - vector with 2 elements\n",
    "        \n",
    "    Outputs:\n",
    "        f - function value (scalar)\n",
    "    '''\n",
    "    # Constants\n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    c = np.array([40, 1, 10])\n",
    "    \n",
    "    # Intermediates. Recall Python indicies start at 0\n",
    "    u = x[0] - 0.8\n",
    "    s = np.sqrt(1-u)\n",
    "    s2 = np.sqrt(1+u)\n",
    "    v = x[1] -(a[0] + a[1]*u**2*s-a[2]*u)\n",
    "    alpha = -b[0] + b[1]*u**2*s2+ b[2]*u # September 5, 2018: changed 's' to 's2'\n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"##### my_f at x = \",x, \"#####\")\n",
    "        print(\"u = \",u)\n",
    "        print(\"sqrt(1-u) = \",s)\n",
    "        print(\"sqrt(1+u) = \",s2)\n",
    "        print(\"v = \",v)\n",
    "        print(\"alpha = \",alpha)\n",
    "        print(\"beta = \",beta)\n",
    "        print(\"f(x) = \",)\n",
    "        print(\"##### Done. #####\\n\")\n",
    "    \n",
    "    return alpha*np.exp(-beta)\n",
    "\n",
    "## Calculate gradient with central finite difference\n",
    "def my_grad_approx(x,f,eps1,verbose=False):\n",
    "    '''\n",
    "    Calculate gradient of function my_f using central difference formula\n",
    "    \n",
    "    Inputs:\n",
    "        x - point for which to evaluate gradient\n",
    "        f - function to consider\n",
    "        eps1 - perturbation size\n",
    "        \n",
    "    Outputs:\n",
    "        grad - gradient (vector)\n",
    "    '''\n",
    "    \n",
    "    n = len(x)\n",
    "    grad = np.zeros(n)\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"***** my_grad_approx at x = \",x,\"*****\")\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        \n",
    "        # Create vector of zeros except eps in position i\n",
    "        e = np.zeros(n)\n",
    "        e[i] = eps1\n",
    "        \n",
    "        # Finite difference formula\n",
    "        my_f_plus = f(x + e)\n",
    "        my_f_minus = f(x - e)\n",
    "        \n",
    "        # Diagnostics\n",
    "        if(verbose):\n",
    "            print(\"e[\",i,\"] = \",e)\n",
    "            print(\"f(x + e[\",i,\"]) = \",my_f_plus)\n",
    "            print(\"f(x - e[\",i,\"]) = \",my_f_minus)\n",
    "        \n",
    "        \n",
    "        grad[i] = (my_f_plus - my_f_minus)/(2*eps1)\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"***** Done. ***** \\n\")\n",
    "    \n",
    "    return grad\n",
    "\n",
    "## Calculate gradient using central finite difference and my_hes_approx\n",
    "def my_hes_approx(x,grad,eps2):\n",
    "    '''\n",
    "    Calculate gradient of function my_f using central difference formula and my_grad\n",
    "    \n",
    "    Inputs:\n",
    "        x - point for which to evaluate gradient\n",
    "        grad - function to calculate the gradient\n",
    "        eps2 - perturbation size (for Hessian NOT gradient approximation)\n",
    "        \n",
    "    Outputs:\n",
    "        H - Hessian (matrix)\n",
    "    '''\n",
    "    \n",
    "    n = len(x)\n",
    "    H = np.zeros([n,n])\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        # Create vector of zeros except eps in position i\n",
    "        e = np.zeros(n)\n",
    "        e[i] = eps2\n",
    "        \n",
    "        # Evaluate gradient twice\n",
    "        grad_plus = grad(x + e)\n",
    "        grad_minus = grad(x - e)\n",
    "        \n",
    "        # Notice we are building the Hessian by column (or row)\n",
    "        H[:,i] = (grad_plus - grad_minus)/(2*eps2)\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.1 Finite Difference Code](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.1-Finite-Difference-Code)",
     "section": "3.9.1.2.1 Finite Difference Code"
    }
   },
   "outputs": [],
   "source": [
    "### Test the functions from above\n",
    "\n",
    "## Define test point\n",
    "xt = np.array([0,0])\n",
    "print(\"xt = \",xt,\"\\n\")\n",
    "\n",
    "print(\"f(xt) = \\n\",my_f([0,0]),\"\\n\")\n",
    "\n",
    "## Compute gradient\n",
    "g = my_grad_approx(xt,my_f,1E-6)\n",
    "print(\"grad(xt) = \",g,\"\\n\")\n",
    "\n",
    "## Compute Hessian\n",
    "# Step 1: Create a Lambda (anonymous) function\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Step 2: Calculate Hessian approximation\n",
    "H = my_hes_approx(xt,calc_grad,1E-6)\n",
    "print(\"hes(xt) = \\n\",H,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.2 Analytic Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.2-Analytic-Gradient)",
     "section": "3.9.1.2.2 Analytic Gradient"
    }
   },
   "source": [
    "#### 3.9.1.2.2 Analytic Gradient\n",
    "\n",
    "It turns out the calculating the analytic gradient with Mathematic quickly becomes a mess. Instead, the  following code uses the symbolic computing capabilities in SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.2 Analytic Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.2-Analytic-Gradient)",
     "section": "3.9.1.2.2 Analytic Gradient"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Encoding the exact gradient with the long expression above is very time-consuming. This is a trick of calculating the \n",
    "symbolic derivative and converting it to an analytic function to be evaluated at a point. \n",
    "'''\n",
    "\n",
    "# Define function to use with symbolic computing framework\n",
    "def f(x1,x2):\n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    b1 = 5;\n",
    "    c = np.array([40, 1, 10])\n",
    "    u = x1 - 0.8\n",
    "    v = x2 -(a[0] + a[1]*u**2*(1-u)**0.5-a[2]*u)\n",
    "    alpha = b[1]*u**2*(1+u)**0.5 + b[2]*u -b[0]\n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    return alpha*sym.exp(-1*beta)\n",
    "\n",
    "# Define function to use later\n",
    "def my_grad_exact(x):\n",
    "    x1, x2 = sym.symbols('x1 x2')\n",
    "    DerivativeOfF1 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1));\n",
    "    DerivativeOfF2 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2));\n",
    "    #DerivativeOfF2 = sym.lambdify((x1,x2),gradf2(x1,x2));\n",
    "    #F = sym.lambdify((x1,x2),f(x1,x2));\n",
    "    return np.array([DerivativeOfF1(x[0],x[1]),DerivativeOfF2(x[0],x[1])])\n",
    "    \n",
    "x = np.array([0,0])\n",
    "print(\"The exact gradient is \\n\",my_grad_exact(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.3 Analytic Hessian](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.3-Analytic-Hessian)",
     "section": "3.9.1.2.3 Analytic Hessian"
    }
   },
   "source": [
    "#### 3.9.1.2.3 Analytic Hessian\n",
    "\n",
    "The code below assembles the analytic Hessian using the symbolic computing framework in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 4,
     "link": "[3.9.1.2.3 Analytic Hessian](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.2.3-Analytic-Hessian)",
     "section": "3.9.1.2.3 Analytic Hessian"
    }
   },
   "outputs": [],
   "source": [
    "def f(x1,x2):\n",
    "    \n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    b1 = 5;\n",
    "    c = np.array([40, 1, 10])\n",
    "    u = x1 - 0.8\n",
    "    v = x2 -(a[0] + a[1]*u**2*(1-u)**0.5-a[2]*u)\n",
    "    alpha = b[1]*u**2*(1+u)**0.5 + b[2]*u -b[0]\n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    return alpha*sym.exp(-1*beta)\n",
    "\n",
    "\n",
    "def my_hes_exact(x):\n",
    "    x1, x2 = sym.symbols('x1 x2')\n",
    "    HessianOfF11 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1,x1));\n",
    "    HessianOfF12 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1,x2));\n",
    "    HessianOfF21 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2,x1));\n",
    "    HessianOfF22 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2,x2));\n",
    "    #DerivativeOfF2 = sym.lambdify((x1,x2),gradf2(x1,x2));\n",
    "    #F = sym.lambdify((x1,x2),f(x1,x2));\n",
    "    return np.array([[HessianOfF11(x[0],x[1]),HessianOfF12(x[0],x[1])],[HessianOfF21(x[0],x[1]),HessianOfF22(x[0],x[1])]])\n",
    "    \n",
    "x = np.array([0,0])\n",
    "print(\"The exact Hessian is \\n\",my_hes_exact(x))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.3 Gradient Finite Difference Comparison](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.3-Gradient-Finite-Difference-Comparison)",
     "section": "3.9.1.3 Gradient Finite Difference Comparison"
    }
   },
   "source": [
    "### 3.9.1.3 Gradient Finite Difference Comparison\n",
    "\n",
    "Repeat the analysis procedure from the finite difference class notebook to find the value of $\\epsilon_1$ that gives the smallest approximation error. Some tips:\n",
    "1. Write a `for` loop to iterate over many values of $\\epsilon_1$\n",
    "2. Use $|| \\nabla f(x;\\epsilon_1)_{approx} - \\nabla f(x)_{exact} ||$ to measure the error. Your choice on which norm(s) to use. Please label your plot with the norm(s) you used.\n",
    "3. Make a log-log plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.3 Gradient Finite Difference Comparison](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.3-Gradient-Finite-Difference-Comparison)",
     "section": "3.9.1.3 Gradient Finite Difference Comparison"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.4 Hessian Finite Difference using Approximate Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.4-Hessian-Finite-Difference-using-Approximate-Gradient)",
     "section": "3.9.1.4 Hessian Finite Difference using Approximate Gradient"
    }
   },
   "source": [
    "### 3.9.1.4 Hessian Finite Difference using Approximate Gradient\n",
    "\n",
    "Repeat the analysis from above. Use `my_grad_approx` and the best value for $\\epsilon_1$ you previously found. What value of $\\epsilon_2$ gives the lowest Hessian approximation error? Note: $\\epsilon_1$ is used in the gradient approximation and $\\epsilon_2$ is used in the Hessian approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.4 Hessian Finite Difference using Approximate Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.4-Hessian-Finite-Difference-using-Approximate-Gradient)",
     "section": "3.9.1.4 Hessian Finite Difference using Approximate Gradient"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.5 Hessian Finite Difference using Exact Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.5-Hessian-Finite-Difference-using-Exact-Gradient)",
     "section": "3.9.1.5 Hessian Finite Difference using Exact Gradient"
    }
   },
   "source": [
    "### 3.9.1.5 Hessian Finite Difference using Exact Gradient\n",
    "\n",
    "Repeat the analysis from above using `my_grad_exact`. What value of $\\epsilon_2$ gives the lower Hessian approximation error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.5 Hessian Finite Difference using Exact Gradient](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.5-Hessian-Finite-Difference-using-Exact-Gradient)",
     "section": "3.9.1.5 Hessian Finite Difference using Exact Gradient"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.6 Final Answers](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.6-Final-Answers)",
     "section": "3.9.1.6 Final Answers"
    }
   },
   "source": [
    "### 3.9.1.6 Final Answers\n",
    "\n",
    "**Record your final answers below**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.6 Final Answers](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.6-Final-Answers)",
     "section": "3.9.1.6 Final Answers"
    }
   },
   "source": [
    "A. Using $\\epsilon_1 = $ ... gives error $|| \\nabla f(x;\\epsilon_1)_{approx} - \\nabla f(x)_{exact} || = $ ...\n",
    "\n",
    "B. Using $\\epsilon_1 = $ ... and $\\epsilon_2 = $ ... gives error $|| \\nabla^2 f(x;\\epsilon_1,\\epsilon_2)_{approx} - \\nabla^2 f(x)_{exact} || = $ ...\n",
    "\n",
    "C. Using $\\epsilon_2 = $ gives error $|| \\nabla^2 f(x;\\epsilon_2)_{approx} - \\nabla^2 f(x)_{exact} || = $ ...\n",
    "\n",
    "These answers were computed using the ... norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.7-Discussion)",
     "section": "3.9.1.7 Discussion"
    }
   },
   "source": [
    "### 3.9.1.7 Discussion\n",
    "\n",
    "What is the benefit of using the *exact gradient* when approximating the Hessian with central finite difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.1.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.1.7-Discussion)",
     "section": "3.9.1.7 Discussion"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.2 Analysis of possible optimization solutions](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2-Analysis-of-possible-optimization-solutions)",
     "section": "3.9.2 Analysis of possible optimization solutions"
    }
   },
   "source": [
    "## 3.9.2 Analysis of possible optimization solutions\n",
    "\n",
    "Consider the following optimization problem:\n",
    "\n",
    "$$\\min f(x) := \\left[x_1^2 + (x_2 + 1)^2\\right] \\cdot \\left[x_1^2 + (x_2 - 1)^2\\right]$$\n",
    "\n",
    "Our optimization algorithm terminates at the following points:\n",
    "1. $x = [0,0]^T$\n",
    "2. $x = [0,1]^T$\n",
    "3. $x = [0,-1]^T$\n",
    "4. $x = [1,1]^T$\n",
    "\n",
    "Classify each point.\n",
    "\n",
    "You may solve this problem entirely on paper, entirely in Python, or some combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.2 Analysis of possible optimization solutions](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2-Analysis-of-possible-optimization-solutions)",
     "section": "3.9.2 Analysis of possible optimization solutions"
    }
   },
   "source": [
    "**Suggested solution approach: define systematic analysis routine**\n",
    "\n",
    "Create a function that:\n",
    "1. Evaluates $f(x)$, $\\nabla f(x)$, and $\\nabla^2 f(x)$ for a given $x$\n",
    "2. Calculates eigenvalues of $\\nabla^2 f(x)$\n",
    "\n",
    "We then reuse this function at analyze each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.2 Analysis of possible optimization solutions](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2-Analysis-of-possible-optimization-solutions)",
     "section": "3.9.2 Analysis of possible optimization solutions"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.1 Point 1](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.1-Point-1)",
     "section": "3.9.2.1 Point 1"
    }
   },
   "source": [
    "### 3.9.2.1 Point 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.1 Point 1](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.1-Point-1)",
     "section": "3.9.2.1 Point 1"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.1 Point 1](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.1-Point-1)",
     "section": "3.9.2.1 Point 1"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.2 Point 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.2-Point-2)",
     "section": "3.9.2.2 Point 2"
    }
   },
   "source": [
    "### 3.9.2.2 Point 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.2 Point 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.2-Point-2)",
     "section": "3.9.2.2 Point 2"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.2 Point 2](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.2-Point-2)",
     "section": "3.9.2.2 Point 2"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.3 Point 3](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.3-Point-3)",
     "section": "3.9.2.3 Point 3"
    }
   },
   "source": [
    "### 3.9.2.3 Point 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.3 Point 3](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.3-Point-3)",
     "section": "3.9.2.3 Point 3"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.3 Point 3](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.3-Point-3)",
     "section": "3.9.2.3 Point 3"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.4 Point 4](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.4-Point-4)",
     "section": "3.9.2.4 Point 4"
    }
   },
   "source": [
    "### 3.9.2.4 Point 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.4 Point 4](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.4-Point-4)",
     "section": "3.9.2.4 Point 4"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.4 Point 4](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.4-Point-4)",
     "section": "3.9.2.4 Point 4"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.5 Visualize in 3D](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.5-Visualize-in-3D)",
     "section": "3.9.2.5 Visualize in 3D"
    }
   },
   "source": [
    "### 3.9.2.5 Visualize in 3D\n",
    "\n",
    "Plot $f(x)$ in 3D over the domain $x_1 \\in [-1.1,1.1]$ and $x_2 \\in [-1.5, 1.5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.5 Visualize in 3D](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.5-Visualize-in-3D)",
     "section": "3.9.2.5 Visualize in 3D"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.2.6 Convexity](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.2.6-Convexity)",
     "section": "3.9.2.6 Convexity"
    }
   },
   "source": [
    "### 3.9.2.6 Convexity\n",
    "\n",
    "\n",
    "Is $f(x)$ convex? Did you need to make the plot to make this determination? Write a sentence or two to justify your answer.\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 2,
     "link": "[3.9.3 Multivariable Taylor Series](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3-Multivariable-Taylor-Series)",
     "section": "3.9.3 Multivariable Taylor Series"
    }
   },
   "source": [
    "## 3.9.3 Multivariable Taylor Series\n",
    "\n",
    "You will use `my_grad_exact`, `my_grad_approx`, `my_hes_exact`, and `my_hes_approx` to construct Taylor series approximations to an arbitrary twice differentiable continuous functions with inputs $x \\in \\mathbb{R}^2$. We will then look consider Example 2.19 and visualize the Taylor series approximation in 3D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.1-Create-a-function-to-plot-the-first-order-Taylor-series-using-$\\nabla-f$)",
     "section": "3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$"
    }
   },
   "source": [
    "### 3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$\n",
    "\n",
    "Create a general function that:\n",
    "1. Constructs constructs a Taylor series using $\\nabla f$ centered around a give point\n",
    "2. Plots the true function and Taylor series approximation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.1-Create-a-function-to-plot-the-first-order-Taylor-series-using-$\\nabla-f$)",
     "section": "3.9.3.1 Create a function to plot the first order Taylor series using $\\nabla f$"
    }
   },
   "outputs": [],
   "source": [
    "def taylor1(xc, f, grad, dx):\n",
    "    '''\n",
    "    Constructs a Taylor series using first derivates and visualizes in 3D\n",
    "    \n",
    "    Arguments:\n",
    "        xc - point to center Taylor series\n",
    "        f - function that computes function value. Only has one input (x)\n",
    "        grad - function that computes gradient. Only has one input (x)\n",
    "        dx - list or numpy array. creates 3D plot over xc[0] +/- dx[0], xc[1] +/- dx[1]\n",
    "    \n",
    "    Returns:\n",
    "        none\n",
    "        \n",
    "    Actions:\n",
    "        3D plot\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.2 Taylor Series using `my_grad_approx`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.2-Taylor-Series-using-`my_grad_approx`)",
     "section": "3.9.3.2 Taylor Series using `my_grad_approx`"
    }
   },
   "source": [
    "### 3.9.3.2 Taylor Series using `my_grad_approx`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.5, 0.5]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.2 Taylor Series using `my_grad_approx`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.2-Taylor-Series-using-`my_grad_approx`)",
     "section": "3.9.3.2 Taylor Series using `my_grad_approx`"
    }
   },
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.5, 0.5]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor1(xc, my_f, calc_grad, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.3 Taylor Series using `my_grad_exact`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.3-Taylor-Series-using-`my_grad_exact`)",
     "section": "3.9.3.3 Taylor Series using `my_grad_exact`"
    }
   },
   "source": [
    "### 3.9.3.3 Taylor Series using `my_grad_exact`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.5, 0.5]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.3 Taylor Series using `my_grad_exact`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.3-Taylor-Series-using-`my_grad_exact`)",
     "section": "3.9.3.3 Taylor Series using `my_grad_exact`"
    }
   },
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_exact(x)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.5, 0.5]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor1(xc, my_f, calc_grad, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.4-Create-a-function-to-plot-the-second-order-Taylor-series-using-$\\nabla-f$-and-$\\nabla^2-f$)",
     "section": "3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$"
    }
   },
   "source": [
    "### 3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.4-Create-a-function-to-plot-the-second-order-Taylor-series-using-$\\nabla-f$-and-$\\nabla^2-f$)",
     "section": "3.9.3.4 Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$"
    }
   },
   "outputs": [],
   "source": [
    "def taylor2(xc, f, grad, hes, dx):\n",
    "    '''\n",
    "    Constructs a Taylor series using first derivates and visualizes in 3D\n",
    "    \n",
    "    Inputs:\n",
    "        xc - point to center Taylor series\n",
    "        f - computes function value. Only has one input (x)\n",
    "        grad - computes gradient. Only has one input (x)\n",
    "        hes - computes the Hessian. Only has one input (x)\n",
    "        dx - creates 3D plot over xc[0] +/- dx[0], xc[1] +/- dx[1]\n",
    "    \n",
    "    Outputs:\n",
    "        none\n",
    "        \n",
    "    Creates:\n",
    "        3D plot\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### Evaluates function and gradiant\n",
    "    fval = f(xc)\n",
    "    gval = grad(xc)\n",
    "    Hval = hes(xc)\n",
    "    \n",
    "    ### Creates domain for plotting\n",
    "    x1 = np.arange(xc[0] - dx[0],xc[0] + dx[0],dx[0]/100)\n",
    "    x2 = np.arange(xc[1] - dx[1],xc[1] + dx[1],dx[1]/100)\n",
    "    \n",
    "    ## Create a matrix of all points to sample\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "    n1 = len(x1)\n",
    "    n2 = len(x2)\n",
    "\n",
    "    ## Allocate matrix for true function value\n",
    "    F = np.zeros([n2, n1])\n",
    "\n",
    "    ## Allocate matrix for Taylor series approximation\n",
    "    T = np.zeros([n2, n1])    \n",
    "    \n",
    "    xtemp = np.zeros(2)\n",
    "\n",
    "    # Evaluate f(x) and Taylor series over grid\n",
    "    for i in range(0,n1):\n",
    "        xtemp[0] = x1[i]\n",
    "        for j in range(0,n2):\n",
    "            xtemp[1] = x2[j]\n",
    "            \n",
    "            # Evaluate f(x)\n",
    "            F[j,i] = my_f(xtemp)\n",
    "\n",
    "            # Evaluate Taylor series\n",
    "            dx_ = xtemp - xc\n",
    "            \n",
    "            '''\n",
    "            print(\"dx = \",dx)\n",
    "            print(\"gval = \",gval)\n",
    "            print(\"Hval = \",Hval)\n",
    "            '''\n",
    "            \n",
    "            temp = Hval.dot(dx_)\n",
    "            # print(\"Hval * dx = \",temp)\n",
    "            \n",
    "            \n",
    "            # T[j,i] = fval + gval.dot(dx_) + 0.5*(temp).dot(dx_)\n",
    "            T[j,i] = fval + gval.dot(dx_) + 0.5*(dx_.dot(Hval.dot(dx_)))\n",
    "            \n",
    "    # Create 3D figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Plot f(x)\n",
    "    surf = ax.plot_surface(X1, X2, F, linewidth=0,cmap=cm.coolwarm,antialiased=True,label=\"f(x)\")\n",
    "\n",
    "    # Plot Taylor series approximation\n",
    "    surf = ax.plot_surface(X1, X2, T, linewidth=0,cmap=cm.PiYG,antialiased=True,label=\"Taylor series\")\n",
    "    \n",
    "    # Add candidate point\n",
    "    ax.scatter(xc[0],xc[1],fval,s=50,color=\"black\",depthshade=True)\n",
    "\n",
    "    # Draw vertical line through stationary point to help visualization\n",
    "    # Maximum value in array\n",
    "    fmax = np.amax(F)\n",
    "    fmin = np.amin(F)\n",
    "    ax.plot([xc[0], xc[0]], [xc[1], xc[1]], [fmin,fmax],color=\"black\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.5-Taylor-series-using-`my_grad_approx`-and-`my_hes_approx`)",
     "section": "3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`"
    }
   },
   "source": [
    "### 3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.2, 0.2]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.5-Taylor-series-using-`my_grad_approx`-and-`my_hes_approx`)",
     "section": "3.9.3.5 Taylor series using `my_grad_approx` and `my_hes_approx`"
    }
   },
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Specify epsilon2\n",
    "calc_hes = lambda x : my_hes_approx(x, calc_grad, 1E-6)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.2, 0.2]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor2(xc, my_f, calc_grad, calc_hes, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.6-Taylor-series-using-`my_grad_exact`-and-`my_hes_exact`)",
     "section": "3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`"
    }
   },
   "source": [
    "### 3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.2, 0.2]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.6-Taylor-series-using-`my_grad_exact`-and-`my_hes_exact`)",
     "section": "3.9.3.6 Taylor series using `my_grad_exact` and `my_hes_exact`"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([0,0])\n",
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_exact(x)\n",
    "\n",
    "# Specify epsilon2\n",
    "calc_hes = lambda x1 : my_hes_exact(x1)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.2, 0.2]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor2(xc, my_f, calc_grad, calc_hes, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "### 3.9.3.7 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "Write 1 or 2 sentences to describe the the shapes for the first order and second order Taylor series approximations? Why do these shapes make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "Is there a visible different to the Taylor series approximations using the finite difference versus exact derivatives? Why does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpages": {
     "level": 3,
     "link": "[3.9.3.7 Discussion](https://ndcbe.github.io/CBE60499/03.09-Algorithms2.html#3.9.3.7-Discussion)",
     "section": "3.9.3.7 Discussion"
    }
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [3.8 Algorithms 1 Homework](https://ndcbe.github.io/CBE60499/03.08-Algorithms1.html) | [Contents](toc.html) | [4.0 Constrained Nonlinear Optimization: Theory and Applications](https://ndcbe.github.io/CBE60499/04.00-Constrained.html) ><p><a href=\"https://colab.research.google.com/github/ndcbe/CBE60499/blob/master/docs/03.09-Algorithms2.ipynb\"> <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a><p><a href=\"https://ndcbe.github.io/CBE60499/03.09-Algorithms2.ipynb\"> <img align=\"left\" src=\"https://img.shields.io/badge/Github-Download-blue.svg\" alt=\"Download\" title=\"Download Notebook\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
